[
  {
    "role": "user",
    "content": "ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ³ÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦spark"
  },
  {
    "role": "assistant",
    "content": "ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂªÃÂÃÂ¥ÃÂÃÂ¥ÃÂÃÂ½ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ  Apache Spark ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂªÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂ¸ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ©ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ°ÃÂÃÂ¤ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ§ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ©ÃÂÃÂ¢ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂSpark ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂªÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂºÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ§ÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¦ÃÂÃÂºÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ¾ÃÂÃÂ¤ÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¦ÃÂÃÂ¡ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¹ÃÂÃÂ¿ÃÂÃÂ¦ÃÂÃÂ³ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂºÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ ÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂµÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ­ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂºÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ£ÃÂÃÂÃÂÃÂ\n\nÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂ¢ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂª**ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ  Spark ÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¨ÃÂÃÂ·ÃÂÃÂ¯ÃÂÃÂ§ÃÂÃÂºÃÂÃÂ¿ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¾**ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂ®ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ©ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ ÃÂÃÂ§ÃÂÃÂ³ÃÂÃÂ»ÃÂÃÂ§ÃÂÃÂ»ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¡ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n\n---\n\n## ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂºÃÂÃÂ§ÃÂÃÂ¡ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ\n\n### 1. ÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ Java ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ Scala\n- **Java**ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂSpark ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ Scala ÃÂÃÂ§ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ¿ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ Java ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ PythonÃÂÃÂ£ÃÂÃÂÃÂÃÂ\n- **Scala**ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¨ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂº Spark ÃÂÃÂ§ÃÂÃÂÃÂÃÂ API ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ´ÃÂÃÂ¨ÃÂÃÂÃÂÃÂªÃÂÃÂ§ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂ Scala ÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂ\n- **PythonÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂPySparkÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ**ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ´ÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ PythonÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ PySpark ÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ§ÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂ\n\n### 2. ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ£ÃÂÃÂ Java ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ JDK\n- ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ£ÃÂÃÂ [JDK](https://www.oracle.com/java/technologies/downloads/)ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ»ÃÂÃÂºÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ® Java 8 ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ´ÃÂÃÂ©ÃÂÃÂ«ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¬ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n- ÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¾ÃÂÃÂ§ÃÂÃÂ½ÃÂÃÂ®ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¥ÃÂÃÂ¢ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂ `JAVA_HOME`\n\n### 3. ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ£ÃÂÃÂ ScalaÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n- ÃÂÃÂ¥ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ Scala ÃÂÃÂ§ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ Spark ÃÂÃÂ§ÃÂÃÂ¨ÃÂÃÂÃÂÃÂ¥ÃÂÃÂºÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ¥ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ£ÃÂÃÂ [Scala](https://www.scala-lang.org/download/)\n\n### 4. ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ£ÃÂÃÂ Spark\n- ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ½ÃÂÃÂ½ [Apache Spark](https://spark.apache.org/downloads.html)\n- ÃÂÃÂ¨ÃÂÃÂ§ÃÂÃÂ£ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¹ÃÂÃÂ¶ÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¾ÃÂÃÂ§ÃÂÃÂ½ÃÂÃÂ®ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¥ÃÂÃÂ¢ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂ `SPARK_HOME`\n- ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ¿ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ `spark-shell` ÃÂÃÂ¨ÃÂÃÂ¿ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¡ÃÂÃÂÃÂÃÂ¤ÃÂÃÂºÃÂÃÂ¤ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ\n\n---\n\n## ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ  Spark ÃÂÃÂ¦ÃÂÃÂ ÃÂÃÂ¸ÃÂÃÂ¥ÃÂÃÂ¿ÃÂÃÂÃÂÃÂ¦ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¿ÃÂÃÂµ\n\n### 1. ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ SparkÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n- ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂºÃÂÃÂ¦ÃÂÃÂ¦ÃÂÃÂ¯ÃÂÃÂ Hadoop MapReduce ÃÂÃÂ¥ÃÂÃÂ¿ÃÂÃÂ«ÃÂÃÂ¥ÃÂÃÂ¾ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¾ÃÂÃÂ RDDÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂ¹ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ§ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®ÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂDataFrameÃÂÃÂ£ÃÂÃÂÃÂÃÂDataset ÃÂÃÂ§ÃÂÃÂ­ÃÂÃÂ API\n\n### 2. ÃÂÃÂ¥ÃÂÃÂÃÂÃÂºÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¬ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ\n- Driver Program\n- Executor\n- Cluster ManagerÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¦ÃÂÃÂ YARN, Mesos, KubernetesÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n\n### 3. RDDÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂResilient Distributed DatasetÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n- Spark ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂ ÃÂÃÂ¸ÃÂÃÂ¥ÃÂÃÂ¿ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®ÃÂÃÂ§ÃÂÃÂ»ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¨ÃÂÃÂ½ÃÂÃÂ¬ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¢ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂTransformationsÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂActionsÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n\n---\n\n## ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ·ÃÂÃÂµ\n\n### 1. ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ¿ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ spark-shell ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂ¤ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ \n```bash\n$ cd $SPARK_HOME\n$ ./bin/spark-shell\n```\n\n#### ÃÂÃÂ§ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂ¤ÃÂÃÂ¾ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ£ÃÂÃÂ§ÃÂÃÂ ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n```scala\nval data = Array(1, 2, 3, 4, 5)\nval distData = sc.parallelize(data)\ndistData.map(_ * 2).collect()\n```\n\n### 2. ÃÂÃÂ§ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ¬ÃÂÃÂ¬ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂª Spark ÃÂÃÂ¥ÃÂÃÂºÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ§ÃÂÃÂ¨ÃÂÃÂÃÂÃÂ¥ÃÂÃÂºÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂScalaÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n```scala\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkConf\n\nobject WordCount {\n  def main(args: Array[String]): Unit = {\n    val conf = new SparkConf().setAppName(\"WordCount\")\n    val sc = new SparkContext(conf)\n\n    val lines = sc.textFile(\"file:///path/to/your/file.txt\")\n    val words = lines.flatMap(line => line.split(\" \"))\n    val wordCounts = words.map(word => (word, 1)).reduceByKey(_ + 1)\n\n    wordCounts.saveAsTextFile(\"output_path\")\n    sc.stop()\n  }\n}\n```\n\n### 3. ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ¿ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ PySparkÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂPython ÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¬ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n```python\nfrom pyspark import SparkContext\n\nsc = SparkContext(\"local\", \"WordCount\")\nlines = sc.textFile(\"file:///path/to/your/file.txt\")\nwords = lines.flatMap(lambda line: line.split())\nword_counts = words.map(lambda x: (x, 1)).reduceByKey(lambda a, b: a + b)\nword_counts.saveAsTextFile(\"output_path\")\n```\n\n---\n\n## ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¿ÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂ¹\n\n### 1. DataFrame ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ Dataset\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ´ÃÂÃÂ©ÃÂÃÂ«ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂ APIÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ»ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ SQL ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¨ÃÂÃÂ¯ÃÂÃÂ¢\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¨ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ©ÃÂÃÂ¡ÃÂÃÂ¹ÃÂÃÂ§ÃÂÃÂÃÂÃÂ®ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂ­ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ¿ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨\n\n### 2. Spark SQL\n- ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ»ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®\n- ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂ Hive ÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ SQL ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¨ÃÂÃÂ¯ÃÂÃÂ¢ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ DataFrame API\n\n### 3. Spark Streaming\n- ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂ\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ KafkaÃÂÃÂ£ÃÂÃÂÃÂÃÂFlume ÃÂÃÂ§ÃÂÃÂ­ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®ÃÂÃÂ¦ÃÂÃÂºÃÂÃÂ\n\n### 4. Spark MLlib\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂºÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ ÃÂÃÂ¥ÃÂÃÂºÃÂÃÂ\n- ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ«ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ±ÃÂÃÂ»ÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¨ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ±ÃÂÃÂ»ÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ½ÃÂÃÂÃÂÃÂ§ÃÂÃÂ­ÃÂÃÂÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¦ÃÂÃÂ³ÃÂÃÂ\n\n### 5. Spark GraphX\n- ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¾ÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¦ÃÂÃÂ¡ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¶\n- ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂÃÂÃÂ§ÃÂÃÂ¤ÃÂÃÂ¾ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂ¤ÃÂÃÂ§ÃÂÃÂ½ÃÂÃÂÃÂÃÂ§ÃÂÃÂ»ÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¨ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ³ÃÂÃÂ»ÃÂÃÂ§ÃÂÃÂ»ÃÂÃÂÃÂÃÂ§ÃÂÃÂ­ÃÂÃÂ\n\n### 6. ÃÂÃÂ¨ÃÂÃÂ°ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ§ÃÂÃÂ¨ÃÂÃÂÃÂÃÂ½ÃÂÃÂ¤ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ\n- ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂÃÂÃÂ\n- ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂº\n- Shuffle ÃÂÃÂ¤ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ\n- ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ¿ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ§ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂcache / persistÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n\n---\n\n## ÃÂÃÂ¤ÃÂÃÂºÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¨ÃÂÃÂÃÂÃÂÃÂÃÂ¨ÃÂÃÂµÃÂÃÂÃÂÃÂ¦ÃÂÃÂºÃÂÃÂ\n\n### ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ¦ÃÂÃÂ§ÃÂÃÂ±ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n- ÃÂÃÂ£ÃÂÃÂÃÂÃÂLearning SparkÃÂÃÂ£ÃÂÃÂÃÂÃÂ ÃÂÃÂ¢ÃÂÃÂÃÂÃÂ O'Reilly\n- ÃÂÃÂ£ÃÂÃÂÃÂÃÂSpark: The Definitive GuideÃÂÃÂ£ÃÂÃÂÃÂÃÂ ÃÂÃÂ¢ÃÂÃÂÃÂÃÂ Manning Publications\n\n### ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ§ÃÂÃÂºÃÂÃÂ¿ÃÂÃÂ¨ÃÂÃÂ¯ÃÂÃÂ¾ÃÂÃÂ§ÃÂÃÂ¨ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n- [Coursera - Apache Spark](https://www.coursera.org/specializations/apache-spark)\n- [Udemy - Spark for Beginners](https://www.udemy.com/)\n- [edX - Big Data with Spark](https://www.edx.org/)\n\n### ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¹ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂ¡ÃÂÃÂ£ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\n- [Spark ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¹ÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂ¡ÃÂÃÂ£](https://spark.apache.org/docs/latest/)\n\n---\n\n## ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ­ÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂ¸ÃÂÃÂ¨ÃÂÃÂ§ÃÂÃÂÃÂÃÂ©ÃÂÃÂÃÂÃÂ®ÃÂÃÂ©ÃÂÃÂ¢ÃÂÃÂ\n\n### Q: Spark ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ Hadoop ÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂºÃÂÃÂ¥ÃÂÃÂÃÂÃÂ«ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\nA: Spark ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂªÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¦ÃÂÃÂ¡ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂHadoop ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂªÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¹ÃÂÃÂ³ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ°ÃÂÃÂ£ÃÂÃÂÃÂÃÂSpark ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ¥ÃÂÃÂ¨ÃÂÃÂ¿ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¡ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ Hadoop ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ¥ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¬ÃÂÃÂ§ÃÂÃÂ«ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¿ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¡ÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂ\n\n### Q: Spark ÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂºÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ\nA: ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ§ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ°ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ®ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¹ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¦ÃÂÃÂµÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂºÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ ÃÂÃÂ£ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¾ÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ§ÃÂÃÂ®ÃÂÃÂÃÂÃÂ§ÃÂÃÂ­ÃÂÃÂÃÂÃÂ£ÃÂÃÂÃÂÃÂ\n\n---\n\nÃÂÃÂ¥ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¯ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ ÃÂÃÂ§ÃÂÃÂÃÂÃÂ®ÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ§ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ§ÃÂÃÂ¨ÃÂÃÂÃÂÃÂ¨ÃÂÃÂÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¦ÃÂÃÂ¯ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¦ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ Java/Python/ScalaÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¤ÃÂÃÂ»ÃÂÃÂ¥ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂºÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ ÃÂÃÂ¥ÃÂÃÂ®ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂ¶ÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂªÃÂÃÂ¦ÃÂÃÂÃÂÃÂ´ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ·ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂÃÂÃÂ§ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ ÃÂÃÂ¨ÃÂÃÂ®ÃÂÃÂ¡ÃÂÃÂ¥ÃÂÃÂÃÂÃÂ ÃÂÃÂ°ÃÂÃÂÃÂÃÂÃÂÃÂ\n\nÃÂÃÂ©ÃÂÃÂÃÂÃÂÃÂÃÂ¨ÃÂÃÂ¦ÃÂÃÂÃÂÃÂ¦ÃÂÃÂÃÂÃÂÃÂÃÂ¥ÃÂÃÂ¸ÃÂÃÂ®ÃÂÃÂ¤ÃÂÃÂ½ÃÂÃÂ ÃÂÃÂ¨ÃÂÃÂ§ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¤ÃÂÃÂ¸ÃÂÃÂÃÂÃÂ¥ÃÂÃÂ­ÃÂÃÂ¦ÃÂÃÂ¤ÃÂÃÂ¹ÃÂÃÂ ÃÂÃÂ¨ÃÂÃÂ·ÃÂÃÂ¯ÃÂÃÂ¥ÃÂÃÂ¾ÃÂÃÂÃÂÃÂ¥ÃÂÃÂÃÂÃÂÃÂÃÂ¯ÃÂÃÂ¼ÃÂÃÂ"
  },
  {
    "role": "user",
    "content": "ÃÂ¤ÃÂ½ÃÂ ÃÂ¥ÃÂ¥ÃÂ½ÃÂ¯ÃÂ¼ÃÂÃÂ¦ÃÂÃÂÃÂ¦ÃÂÃÂ³ÃÂ¥ÃÂ­ÃÂ¦ÃÂ¤ÃÂ¹ÃÂ spark"
  },
  {
    "role": "assistant",
    "content": "ÃÂ¤ÃÂ½ÃÂ ÃÂ¥ÃÂ¥ÃÂ½ÃÂ¯ÃÂ½ÃÂÃÂ¦ÃÂÃÂÃÂ¤ÃÂ»ÃÂ¬ÃÂ¦ÃÂÃÂ¥ÃÂ§ÃÂ¡ÃÂ®ÃÂ¨ÃÂ®ÃÂ¤ÃÂ¤ÃÂ¸ÃÂÃÂ¤ÃÂ½ÃÂ ÃÂ§ÃÂÃÂÃÂ¥ÃÂ­ÃÂ¦ÃÂ¤ÃÂ¹ÃÂ ÃÂ©ÃÂÃÂÃÂ¦ÃÂ±ÃÂÃÂ¥ÃÂÃÂ§ÃÂ¯ÃÂ½ÃÂ  \nÃÂ¤ÃÂ½ÃÂ ÃÂ§ÃÂÃÂ®ÃÂ¥ÃÂÃÂÃÂ¦ÃÂÃÂ³ÃÂ¥ÃÂ­ÃÂ¦ÃÂ¤ÃÂ¹ÃÂ ÃÂ§ÃÂÃÂÃÂ¤ÃÂ¸ÃÂ»ÃÂ©ÃÂ¢ÃÂÃÂ¦ÃÂÃÂ¯ÃÂ¥ÃÂ¤ÃÂ§ÃÂ¦ÃÂÃÂ°ÃÂ¦ÃÂÃÂ®ÃÂ£ÃÂÃÂSpark ÃÂ¨ÃÂ¿ÃÂÃÂ¦ÃÂÃÂ¯ Python ÃÂ¥ÃÂÃÂ¢ÃÂ¯ÃÂ¼ÃÂ"
  },
  {
    "role": "user",
    "content": "sparksql"
  },
  {
    "role": "assistant",
    "content": "Ã¤Â½Â Ã¥Â¥Â½Ã¯Â¼ÂÃ¥Â¾ÂÃ©Â«ÂÃ¥ÂÂ´Ã¤Â½Â Ã©ÂÂÃ¦ÂÂ©Ã¥Â­Â¦Ã¤Â¹Â  **Spark SQL**Ã£ÂÂSpark SQL Ã¦ÂÂ¯ Apache Spark Ã§ÂÂÃ¤Â¸ÂÃ¤Â¸ÂªÃ¦Â Â¸Ã¥Â¿ÂÃ§Â»ÂÃ¤Â»Â¶Ã¯Â¼ÂÃ¤Â¸ÂÃ©ÂÂ¨Ã§ÂÂ¨Ã¤ÂºÂÃ§Â»ÂÃ¦ÂÂÃ¥ÂÂÃ¦ÂÂ°Ã¦ÂÂ®Ã§ÂÂÃ¥Â¤ÂÃ§ÂÂÃ¥ÂÂÃ¥ÂÂÃ¦ÂÂÃ¯Â¼ÂÃ¦ÂÂ¯Ã¦ÂÂ SQL Ã¦ÂÂ¥Ã¨Â¯Â¢Ã£ÂÂDataFrame API Ã¥ÂÂ Dataset APIÃ¯Â¼ÂÃ©ÂÂÃ¥Â¸Â¸Ã©ÂÂÃ¥ÂÂÃ¥ÂÂÃ¥Â¤Â§Ã¦ÂÂ°Ã¦ÂÂ®Ã¥ÂÂÃ¦ÂÂÃ¥ÂÂÃ¦ÂÂ°Ã¦ÂÂ®Ã¤Â»ÂÃ¥ÂºÂÃ§ÂÂ¸Ã¥ÂÂ³Ã§ÂÂÃ¤Â»Â»Ã¥ÂÂ¡Ã£ÂÂ\n\nÃ¤Â¸ÂÃ©ÂÂ¢Ã¦ÂÂ¯Ã¤Â¸ÂÃ¤Â¸ÂªÃ©ÂÂÃ¥Â¯Â¹ **Spark SQL** Ã§ÂÂÃ¥Â­Â¦Ã¤Â¹Â Ã¨Â·Â¯Ã¥Â¾ÂÃ¦ÂÂÃ¥ÂÂÃ¯Â¼ÂÃ¥Â¸Â®Ã¥ÂÂ©Ã¤Â½Â Ã¤Â»ÂÃ©ÂÂ¶Ã¥Â¼ÂÃ¥Â§ÂÃ§Â³Â»Ã§Â»ÂÃ¥ÂÂ°Ã¦ÂÂÃ¦ÂÂ¡Ã¥Â®ÂÃ¯Â¼Â\n\n---\n\n## Ã°ÂÂÂ¹ Ã¤Â¸ÂÃ£ÂÂÃ¥Â­Â¦Ã¤Â¹Â Ã§ÂÂ®Ã¦Â Â\n\n- Ã§ÂÂÃ¨Â§Â£ Spark SQL Ã§ÂÂÃ¥ÂÂºÃ¦ÂÂ¬Ã¦Â¦ÂÃ¥Â¿ÂµÃ¥ÂÂÃ¦ÂÂ¶Ã¦ÂÂ\n- Ã¦ÂÂÃ¦ÂÂ¡ DataFrame Ã¥ÂÂ Dataset API Ã§ÂÂÃ¤Â½Â¿Ã§ÂÂ¨\n- Ã¨ÂÂ½Ã¥Â¤ÂÃ¤Â½Â¿Ã§ÂÂ¨ SQL Ã¦ÂÂ¥Ã¨Â¯Â¢Ã§Â»ÂÃ¦ÂÂÃ¥ÂÂÃ¦ÂÂ°Ã¦ÂÂ®Ã¯Â¼ÂÃ¥Â¦Â CSVÃ£ÂÂParquetÃ£ÂÂJSONÃ£ÂÂHive Ã¨Â¡Â¨Ã§Â­ÂÃ¯Â¼Â\n- Ã§ÂÂÃ¦ÂÂ Spark SQL Ã§ÂÂÃ¦ÂÂ§Ã¨ÂÂ½Ã¤Â¼ÂÃ¥ÂÂÃ¦ÂÂÃ¥Â·Â§\n- Ã¤ÂºÂÃ¨Â§Â£ Spark SQL Ã¤Â¸Â HiveÃ£ÂÂHadoop Ã§ÂÂÃ¦ÂÂÃ§Â³Â»Ã§Â»ÂÃ§ÂÂÃ©ÂÂÃ¦ÂÂ\n\n---\n\n## Ã°ÂÂÂ¹ Ã¤ÂºÂÃ£ÂÂÃ¥Â­Â¦Ã¤Â¹Â Ã¨Â·Â¯Ã¥Â¾Â\n\n### Ã¢ÂÂ 1. Ã¥ÂÂºÃ§Â¡ÂÃ§ÂÂ¥Ã¨Â¯ÂÃ¥ÂÂÃ¥Â¤Â\n\n#### (1) Java/Scala/Python Ã¥ÂÂºÃ§Â¡Â\n- Ã©ÂÂÃ¦ÂÂ©Ã¤Â¸ÂÃ©ÂÂ¨Ã¨Â¯Â­Ã¨Â¨ÂÃ¯Â¼Â**Scala** Ã¦ÂÂ¯ Spark Ã§ÂÂÃ¥ÂÂÃ§ÂÂÃ¨Â¯Â­Ã¨Â¨ÂÃ¯Â¼ÂÃ¦ÂÂ¨Ã¨ÂÂÃ¤Â¼ÂÃ¥ÂÂÃ¥Â­Â¦Ã¤Â¹Â Ã¯Â¼ÂÃ¤Â¹ÂÃ¥ÂÂ¯Ã¤Â»Â¥Ã§ÂÂ¨ **PythonÃ¯Â¼ÂPySparkÃ¯Â¼Â**Ã£ÂÂ\n- Ã¥Â­Â¦Ã¤Â¹Â Ã¥ÂÂºÃ§Â¡ÂÃ¨Â¯Â­Ã¦Â³ÂÃ£ÂÂÃ©ÂÂÃ¥ÂÂÃ¦ÂÂÃ¤Â½ÂÃ£ÂÂÃ¥ÂÂ½Ã¦ÂÂ°Ã¥Â¼ÂÃ§Â¼ÂÃ§Â¨ÂÃ§Â­ÂÃ£ÂÂ\n\n#### (2) Spark Ã¥ÂÂºÃ§Â¡Â\n- Ã¥Â­Â¦Ã¤Â¼ÂÃ¥Â®ÂÃ¨Â£Â Spark Ã¥ÂÂ PySpark\n- Ã§ÂÂÃ¦ÂÂ RDDÃ£ÂÂDataFrameÃ£ÂÂDataset Ã§ÂÂÃ¥ÂÂºÃ¥ÂÂ«Ã¥ÂÂÃ¤Â½Â¿Ã§ÂÂ¨\n- Ã¤ÂºÂÃ¨Â§Â£ Spark Ã§ÂÂÃ¨Â¿ÂÃ¨Â¡ÂÃ¦Â¨Â¡Ã¥Â¼ÂÃ¯Â¼ÂLocal, YARN, Mesos, KubernetesÃ¯Â¼Â\n\n> Ã°ÂÂÂ Ã¦ÂÂ¨Ã¨ÂÂÃ¨ÂµÂÃ¦ÂºÂÃ¯Â¼Â\n> - [Spark Ã¥Â®ÂÃ¦ÂÂ¹Ã¦ÂÂÃ¦Â¡Â£](https://spark.apache.org/docs/latest/)\n> - [Learning Spark](https://www.oreilly.com/library/view/learning-spark/9781491958193/)\n\n---\n\n### Ã¢ÂÂ 2. Spark SQL Ã¦Â Â¸Ã¥Â¿ÂÃ¥ÂÂÃ¥Â®Â¹\n\n#### (1) DataFrame API Ã¥ÂÂ¥Ã©ÂÂ¨\n- DataFrame Ã§ÂÂÃ¥ÂÂÃ¥Â»ÂºÃ¯Â¼ÂÃ¤Â»Â RDDÃ£ÂÂCSVÃ£ÂÂHive Ã¨Â¡Â¨Ã§Â­ÂÃ¯Â¼Â\n- Ã¥Â¸Â¸Ã§ÂÂ¨Ã¦ÂÂÃ¤Â½ÂÃ¯Â¼Â`select`, `filter`, `groupBy`, `agg`, `join`, `sort`, `distinct`\n- Ã¤Â½Â¿Ã§ÂÂ¨ `withColumn`, `alias`, `cast` Ã§Â­ÂÃ¨Â¿ÂÃ¨Â¡ÂÃ¥ÂÂÃ¦ÂÂÃ¤Â½Â\n\n#### (2) SQL Ã¦ÂÂ¥Ã¨Â¯Â¢\n- Ã¤Â½Â¿Ã§ÂÂ¨ `spark.sql()` Ã¦ÂÂ§Ã¨Â¡Â SQL Ã¨Â¯Â­Ã¥ÂÂ¥\n- Ã¦ÂÂ¯Ã¦ÂÂ SQL Ã¨Â¯Â­Ã¦Â³ÂÃ¯Â¼ÂÃ¥ÂÂÃ¦ÂÂ¬Ã¥Â­ÂÃ¦ÂÂ¥Ã¨Â¯Â¢Ã£ÂÂÃ¨ÂÂÃ¥ÂÂÃ£ÂÂÃ¨Â¿ÂÃ¦ÂÂ¥Ã§Â­Â\n- Ã¥ÂÂ¯Ã¤Â»Â¥Ã¨Â¿ÂÃ¦ÂÂ¥ Hive Ã¨Â¡Â¨Ã¯Â¼ÂÃ©ÂÂÃ¨Â¦ÂÃ©ÂÂÃ§Â½Â® Hive MetastoreÃ¯Â¼Â\n\n#### (3) Ã¦ÂÂ°Ã¦ÂÂ®Ã¦Â Â¼Ã¥Â¼ÂÃ¦ÂÂ¯Ã¦ÂÂ\n- Ã¨Â¯Â»Ã¥ÂÂ CSVÃ£ÂÂJSONÃ£ÂÂParquetÃ£ÂÂORC Ã§Â­ÂÃ¦ÂÂÃ¤Â»Â¶Ã¦Â Â¼Ã¥Â¼Â\n- Ã¨Â¯Â»Ã¥ÂÂ Hive Ã¨Â¡Â¨Ã£ÂÂJDBC Ã¦ÂÂ°Ã¦ÂÂ®Ã¥ÂºÂÃ§Â­Â\n\n#### (4) Ã¦ÂÂ§Ã¨ÂÂ½Ã¤Â¼ÂÃ¥ÂÂ\n- Ã§Â¼ÂÃ¥Â­Â DataFrame / DatasetÃ¯Â¼Â`cache()` / `persist()`Ã¯Â¼Â\n- Ã¤Â½Â¿Ã§ÂÂ¨ `checkpoint()` Ã©ÂÂ¿Ã¥ÂÂÃ©ÂÂ¿Ã¤Â¾ÂÃ¨ÂµÂÃ©ÂÂ¾\n- Ã¤Â¼ÂÃ¥ÂÂ Shuffle Ã¦ÂÂÃ¤Â½Â\n- Ã¥ÂÂ©Ã§ÂÂ¨ Catalyst Ã¤Â¼ÂÃ¥ÂÂÃ¥ÂÂ¨Ã¨ÂÂªÃ¥ÂÂ¨Ã¤Â¼ÂÃ¥ÂÂÃ¦ÂÂ¥Ã¨Â¯Â¢Ã¨Â®Â¡Ã¥ÂÂ\n\n#### (5) Ã¤Â¸Â Hive Ã©ÂÂÃ¦ÂÂ\n- Ã¤Â½Â¿Ã§ÂÂ¨ Hive Ã¨Â¡Â¨Ã¤Â½ÂÃ¤Â¸ÂºÃ¦ÂÂ°Ã¦ÂÂ®Ã¦ÂºÂ\n- Ã¦ÂÂ¯Ã¦ÂÂ Hive UDFÃ£ÂÂHive Ã¥ÂÂ½Ã¦ÂÂ°\n- Ã¥ÂÂ¨ Spark Ã¤Â¸Â­Ã¦ÂÂ§Ã¨Â¡Â HiveQL\n\n---\n\n### Ã¢ÂÂ 3. Ã¥Â®ÂÃ¦ÂÂÃ©Â¡Â¹Ã§ÂÂ®Ã¥Â»ÂºÃ¨Â®Â®\n\n#### (1) Ã¦ÂÂ°Ã¦ÂÂ®Ã¦Â¸ÂÃ¦Â´ÂÃ¤Â¸ÂÃ¥ÂÂÃ¦ÂÂ\n- Ã¤Â»Â CSV Ã¦ÂÂÃ¤Â»Â¶Ã¤Â¸Â­Ã¥ÂÂ Ã¨Â½Â½Ã¦ÂÂ°Ã¦ÂÂ®\n- Ã¦Â¸ÂÃ¦Â´ÂÃ¦ÂÂ°Ã¦ÂÂ®Ã¯Â¼ÂÃ¥ÂÂ»Ã©ÂÂÃ£ÂÂÃ§Â©ÂºÃ¥ÂÂ¼Ã¥Â¤ÂÃ§ÂÂÃ£ÂÂÃ§Â±Â»Ã¥ÂÂÃ¨Â½Â¬Ã¦ÂÂ¢Ã¯Â¼Â\n- Ã¨Â¿ÂÃ¨Â¡ÂÃ§Â»ÂÃ¨Â®Â¡Ã¥ÂÂÃ¦ÂÂÃ¯Â¼ÂÃ¥Â¹Â³Ã¥ÂÂÃ¥ÂÂ¼Ã£ÂÂÃ¦ÂÂÃ¥Â¤Â§Ã¥ÂÂ¼Ã£ÂÂÃ¥ÂÂÃ§Â»ÂÃ¨ÂÂÃ¥ÂÂÃ§Â­ÂÃ¯Â¼Â\n\n#### (2) Ã§ÂÂ¨Ã¦ÂÂ·Ã¨Â¡ÂÃ¤Â¸ÂºÃ¥ÂÂÃ¦ÂÂ\n- Ã¥ÂÂÃ¦ÂÂÃ§ÂÂ¨Ã¦ÂÂ·Ã§ÂÂ¹Ã¥ÂÂ»Ã¦ÂÂ¥Ã¥Â¿ÂÃ£ÂÂÃ¨Â®Â¿Ã©ÂÂ®Ã¨Â®Â°Ã¥Â½Â\n- Ã¤Â½Â¿Ã§ÂÂ¨ Spark SQL Ã¨Â®Â¡Ã§Â®ÂÃ§ÂÂ¨Ã¦ÂÂ·Ã§ÂÂÃ¥Â­ÂÃ§ÂÂÃ£ÂÂÃ¨Â½Â¬Ã¥ÂÂÃ§ÂÂÃ§Â­ÂÃ¦ÂÂÃ¦Â Â\n\n#### (3) Ã¥Â¤Â§Ã¦ÂÂ°Ã¦ÂÂ® ETL Ã¦ÂµÂÃ§Â¨Â\n- Ã¤Â»Â HDFS Ã¦ÂÂ Hive Ã¥ÂÂ Ã¨Â½Â½Ã¦ÂÂ°Ã¦ÂÂ®\n- Ã¨Â½Â¬Ã¦ÂÂ¢Ã£ÂÂÃ¦Â¸ÂÃ¦Â´ÂÃ£ÂÂÃ¨ÂÂÃ¥ÂÂÃ¥ÂÂÃ¤Â¿ÂÃ¥Â­ÂÃ¥ÂÂ° Parquet Ã¦ÂÂ Hive Ã¨Â¡Â¨Ã¤Â¸Â­\n\n---\n\n## Ã°ÂÂÂ¹ Ã¤Â¸ÂÃ£ÂÂÃ¦ÂÂ¨Ã¨ÂÂÃ¥Â­Â¦Ã¤Â¹Â Ã¨ÂµÂÃ¦ÂºÂ\n\n### Ã°ÂÂÂ Ã¤Â¹Â¦Ã§Â±Â\n- **Ã£ÂÂSpark SQL Ã¦ÂÂÃ¥Â¨ÂÃ¦ÂÂÃ¥ÂÂÃ£ÂÂ**Ã¯Â¼ÂSpark SQL Ã¥Â®ÂÃ¦ÂÂ¹Ã¦ÂÂÃ¦Â¡Â£ + Ã¤Â¹Â¦Ã¦ÂÂ¬Ã¯Â¼Â\n- **Ã£ÂÂLearning Spark SQLÃ£ÂÂ**Ã¯Â¼ÂO'ReillyÃ¯Â¼Â\n\n### Ã°ÂÂÂ¥ Ã¨Â§ÂÃ©Â¢ÂÃ¨Â¯Â¾Ã§Â¨Â\n- [Coursera - Apache Spark](https://www.coursera.org/specializations/apache-spark)\n- [Udemy - Spark for Beginners](https://www.udemy.com/)\n- [edX - Big Data with Spark](https://www.edx.org/)\n\n### Ã°ÂÂÂ Ã¥ÂÂ¨Ã§ÂºÂ¿Ã¦ÂÂÃ§Â¨Â\n- [Spark SQL Ã¥Â®ÂÃ¦ÂÂ¹Ã¦ÂÂÃ¦Â¡Â£](https://spark.apache.org/docs/latest/sql-programming-guide.html)\n- [DataCamp - Spark SQL](https://www.datacamp.com/)\n- [Towards Data Science - Spark SQL Ã¦ÂÂÃ§Â¨Â](https://towardsdatascience.com/)\n\n---\n\n## Ã°ÂÂÂ¹ Ã¥ÂÂÃ£ÂÂÃ§Â¤ÂºÃ¤Â¾ÂÃ¤Â»Â£Ã§Â ÂÃ¯Â¼ÂPython / ScalaÃ¯Â¼Â\n\n### Python Ã§Â¤ÂºÃ¤Â¾ÂÃ¯Â¼ÂPySparkÃ¯Â¼Â\n```python\nfrom pyspark.sql import SparkSession\n\n# Ã¥ÂÂÃ¥Â»Âº SparkSession\nspark = SparkSession.builder.appName(\"SparkSQLDemo\").getOrCreate()\n\n# Ã¨Â¯Â»Ã¥ÂÂ CSV Ã¦ÂÂÃ¤Â»Â¶\ndf = spark.read.csv(\"path/to/file.csv\", header=True, inferSchema=True)\n\n# Ã¦ÂÂ¾Ã§Â¤ÂºÃ¥ÂÂÃ¥ÂÂ Ã¨Â¡Â\ndf.show()\n\n# Ã¦ÂÂ¥Ã¨Â¯Â¢Ã¥Â¹Â´Ã©Â¾ÂÃ¥Â¤Â§Ã¤ÂºÂ 30 Ã§ÂÂÃ§ÂÂ¨Ã¦ÂÂ·\ndf.filter(df[\"age\"] > 30).show()\n\n# Ã§Â»ÂÃ¨Â®Â¡Ã¥ÂÂÃ¥Â¹Â´Ã©Â¾ÂÃ¦Â®ÂµÃ¤ÂºÂºÃ¦ÂÂ°\ndf.groupBy(\"age\").count().show()\n```\n\n### Scala Ã§Â¤ÂºÃ¤Â¾Â\n```scala\nval df = spark.read.option(\"header\", \"true\").csv(\"path/to/file.csv\")\ndf.show()\n\ndf.filter(df(\"age\") > 30).show()\n\ndf.groupBy(\"age\").count().show()\n```\n\n---\n\n## Ã°ÂÂÂ¹ Ã¤ÂºÂÃ£ÂÂÃ¥Â¸Â¸Ã¨Â§ÂÃ©ÂÂ®Ã©Â¢Â\n\n### Q: Spark SQL Ã¥ÂÂ Hive Ã¦ÂÂÃ¤Â»ÂÃ¤Â¹ÂÃ¥ÂÂºÃ¥ÂÂ«Ã¯Â¼Â\nA: Spark SQL Ã¦ÂÂ¯ Spark Ã§ÂÂÃ¤Â¸ÂÃ©ÂÂ¨Ã¥ÂÂÃ¯Â¼ÂÃ¥ÂÂ¯Ã¤Â»Â¥Ã©Â«ÂÃ¦ÂÂÃ¥ÂÂ°Ã¥Â¤ÂÃ§ÂÂÃ§Â»ÂÃ¦ÂÂÃ¥ÂÂÃ¦ÂÂ°Ã¦ÂÂ®Ã¯Â¼ÂÃ¨ÂÂ Hive Ã¦ÂÂ¯ Hadoop Ã§ÂÂÃ¦ÂÂÃ¤Â¸Â­Ã§ÂÂÃ¦ÂÂ°Ã¦ÂÂ®Ã¤Â»ÂÃ¥ÂºÂÃ¥Â·Â¥Ã¥ÂÂ·Ã£ÂÂSpark SQL Ã¥ÂÂ¯Ã¤Â»Â¥Ã§ÂÂ´Ã¦ÂÂ¥Ã¨Â¯Â»Ã¥ÂÂ Hive Ã¨Â¡Â¨Ã¯Â¼ÂÃ¥Â¹Â¶Ã¤Â¸ÂÃ¦ÂÂ§Ã¨ÂÂ½Ã¦ÂÂ´Ã¤Â¼ÂÃ£ÂÂ\n\n### Q: Spark SQL Ã©ÂÂÃ¥ÂÂÃ¤Â»ÂÃ¤Â¹ÂÃ¥ÂÂºÃ¦ÂÂ¯Ã¯Â¼Â\nA: Ã©ÂÂÃ¥ÂÂÃ¥Â¤ÂÃ§ÂÂÃ§Â»ÂÃ¦ÂÂÃ¥ÂÂÃ¦ÂÂÃ¥ÂÂÃ§Â»ÂÃ¦ÂÂÃ¥ÂÂÃ¦ÂÂ°Ã¦ÂÂ®Ã¯Â¼ÂÃ¦Â¯ÂÃ¥Â¦ÂÃ¦ÂÂ¥Ã¥Â¿ÂÃ¥ÂÂÃ¦ÂÂÃ£ÂÂÃ§ÂÂ¨Ã¦ÂÂ·Ã¨Â¡ÂÃ¤Â¸ÂºÃ¥ÂÂÃ¦ÂÂÃ£ÂÂETL Ã§Â­ÂÃ£ÂÂ\n\n---\n\nÃ¥Â¦ÂÃ¦ÂÂÃ¤Â½Â Ã¦ÂÂ¯Ã¥ÂÂÃ¥Â­Â¦Ã¨ÂÂÃ¯Â¼ÂÃ¥Â»ÂºÃ¨Â®Â®Ã¤Â»Â **PySpark** Ã¥Â¼ÂÃ¥Â§ÂÃ¯Â¼ÂÃ¥ÂÂ Ã¤Â¸Âº Python Ã¦ÂÂ´Ã¥Â®Â¹Ã¦ÂÂÃ¤Â¸ÂÃ¦ÂÂÃ¯Â¼ÂÃ¨ÂÂÃ¤Â¸ÂÃ§Â¤Â¾Ã¥ÂÂºÃ¨ÂµÂÃ¦ÂºÂÃ¤Â¸Â°Ã¥Â¯ÂÃ£ÂÂÃ§Â­ÂÃ§ÂÂÃ¦ÂÂÃ¤Â¹ÂÃ¥ÂÂÃ¯Â¼ÂÃ¥ÂÂÃ¦Â·Â±Ã¥ÂÂ¥Ã¥Â­Â¦Ã¤Â¹Â  Scala Ã§ÂÂÃ¦ÂÂ¬Ã§ÂÂ Spark SQLÃ£ÂÂ\n\nÃ©ÂÂÃ¨Â¦ÂÃ¦ÂÂÃ¥Â¸Â®Ã¤Â½Â Ã¥ÂÂ¶Ã¥Â®ÂÃ¤Â¸ÂÃ¤Â¸ÂªÃ¥ÂÂ·Ã¤Â½ÂÃ§ÂÂÃ¥Â­Â¦Ã¤Â¹Â Ã¨Â®Â¡Ã¥ÂÂÃ¥ÂÂÃ¯Â¼ÂÃ¦ÂÂÃ¨ÂÂÃ¦ÂÂ³Ã¤ÂºÂÃ¨Â§Â£Ã¦ÂÂÃ¤Â¸ÂªÃ¥ÂÂ·Ã¤Â½ÂÃ§ÂÂ¥Ã¨Â¯ÂÃ§ÂÂ¹Ã¯Â¼ÂÃ¦Â¯ÂÃ¥Â¦Â `DataFrame`Ã£ÂÂ`SQL`Ã£ÂÂ`Hive Ã©ÂÂÃ¦ÂÂ`Ã¯Â¼ÂÃ¯Â¼ÂÃ¦Â¬Â¢Ã¨Â¿ÂÃ§Â»Â§Ã§Â»Â­Ã©ÂÂ®Ã¦ÂÂ Ã°ÂÂÂ"
  },
  {
    "role": "user",
    "content": "ææ¯æ³ç²¾è¿æè½"
  },
  {
    "role": "assistant",
    "content": "å¤ªå¥½äºï¼ä½ å·²ç»æç¡®äºâ**ç²¾è¿æè½**âçç®æ ï¼æ¥ä¸æ¥æä»¬å¯ä»¥ä¸ºä½ å®å¶ä¸ä¸ª**ç³»ç»åãåé¶æ®µ**ç **Spark SQL å­¦ä¹ è®¡å**ï¼å¸®å©ä½ ä»åºç¡å°å®æï¼éæ­¥æåå¯¹ Spark SQL çææ¡è½åã\n\n---\n\n## ð¯ ä¸ãå­¦ä¹ ç®æ ï¼ç²¾è¿æè½ï¼\n\n| é¶æ®µ | ç®æ  |\n|------|------|\n| **1. åºç¡å·©åº** | çè§£ Spark SQL æ ¸å¿æ¦å¿µï¼ææ¡ DataFrame å Dataset APIï¼çæ SQL æ¥è¯¢ |\n| **2. å®æåºç¨** | è½å¤ä½¿ç¨ Spark SQL è¿è¡ ETLãæ°æ®æ¸æ´ãç»è®¡åæç­æä½ |\n| **3. æ§è½ä¼å** | ææ¡ Spark SQL çæ§è½è°ä¼æå·§ï¼å¦ç¼å­ãååºãShuffle ä¼åç­ |\n| **4. é«çº§åºç¨** | çæä¸ HiveãHadoop çæéæï¼çè§£ Catalyst ä¼åå¨ãTungsten åå­ç®¡çç­åºå±æºå¶ |\n\n---\n\n## ð äºãå­¦ä¹ è·¯å¾ï¼åé¶æ®µï¼\n\n### â ç¬¬ä¸é¶æ®µï¼åºç¡å·©åºï¼1-2 å¨ï¼\n\n#### 1.1 åºç¡ç¥è¯åå¤\n- **ç¼ç¨è¯­è¨**ï¼\n  - Python æ Scalaï¼æ¨è Pythonï¼éååå­¦èï¼\n  - ææ¡åºæ¬è¯­æ³ãéåæä½ãå½æ°å¼ç¼ç¨\n- **Spark å¥é¨**ï¼\n  - å®è£ Spark + PySpark\n  - çæ RDDãDataFrameãDataset çåºå«\n  - äºè§£ Spark çè¿è¡æ¨¡å¼ï¼Local, YARN, Kubernetes ç­ï¼\n\n> ð æ¨èèµæºï¼\n> - [Spark å®æ¹ææ¡£](https://spark.apache.org/docs/latest/)\n> - [Learning Spark](https://www.oreilly.com/library/view/learning-spark/9781491958193/)\n\n---\n\n#### 1.2 Spark SQL æ ¸å¿åå®¹\n- DataFrame API åºç¡\n  - åå»º DataFrameï¼CSVãHive è¡¨ãRDD ç­ï¼\n  - å¸¸ç¨æä½ï¼`select`, `filter`, `groupBy`, `agg`, `join`, `sort`, `distinct`\n- SQL æ¥è¯¢\n  - ä½¿ç¨ `spark.sql()` æ§è¡ SQL è¯­å¥\n  - æ¯æå­æ¥è¯¢ãèåãè¿æ¥ç­\n- æ°æ®æ ¼å¼æ¯æ\n  - è¯»å CSVãJSONãParquetãORC ç­\n  - è¯»å Hive è¡¨ï¼ééç½® Hive Metastoreï¼\n\n> ð¡ ç¤ºä¾ä»£ç ï¼Pythonï¼ï¼\n```python\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName(\"Demo\").getOrCreate()\ndf = spark.read.csv(\"data.csv\", header=True, inferSchema=True)\ndf.show()\n```\n\n---\n\n### â ç¬¬äºé¶æ®µï¼å®æåºç¨ï¼2-3 å¨ï¼\n\n#### 2.1 å®æé¡¹ç®å»ºè®®\n- **é¡¹ç® 1ï¼ç¨æ·è¡ä¸ºåæ**\n  - ä»æ¥å¿æä»¶ä¸­è§£æç¨æ·ç¹å»è¡ä¸º\n  - è®¡ç®ç¨æ·çå­çãè½¬åçç­ææ \n- **é¡¹ç® 2ï¼ETL æµç¨**\n  - ä» HDFS æ Hive å è½½åå§æ°æ®\n  - æ¸æ´ãè½¬æ¢ãèååä¿å­ä¸º Parquet æ Hive è¡¨\n- **é¡¹ç® 3ï¼å®æ¶åæï¼å¯éï¼**\n  - ç»å Spark Streaming è¯»å Kafka æ¶æ¯\n  - å®æ¶ç»è®¡ãåè­¦ç­\n\n> ð§  æå·§æç¤ºï¼\n> - å¤ä½¿ç¨ `explain()` æ¥çæ§è¡è®¡å\n> - ç¨ `cache()` / `persist()` æåæ§è½\n> - ç¨ `checkpoint()` é¿åé¿ä¾èµé¾\n\n---\n\n### â ç¬¬ä¸é¶æ®µï¼æ§è½ä¼åï¼1-2 å¨ï¼\n\n#### 3.1 Spark SQL æ§è½ä¼åæå·§\n- ç¼å­ç­ç¥ï¼`cache()` vs `persist()`ï¼\n- ååºä¸æåºï¼`repartition()`, `coalesce()`ï¼\n- Shuffle ä¼åï¼åå° Shuffle æ°æ®éï¼\n- Catalyst ä¼åå¨åçç®ä»\n- Tungsten åå­ç®¡çæºå¶ï¼ç¨äºæåæ§è½ï¼\n\n#### 3.2 è°è¯ä¸çæ§\n- ä½¿ç¨ Spark Web UI æ¥çä»»å¡æ§è¡æåµ\n- ä¼å Shuffle è¯»åæç\n- ä½¿ç¨ `broadcast()` ä¼åå°è¡¨è¿æ¥\n\n> ð§© å·¥å·æ¨èï¼\n> - Spark Web UIï¼http://localhost:4040ï¼\n> - JConsoleãVisualVM ç­ JVM çæ§å·¥å·\n\n---\n\n### â ç¬¬åé¶æ®µï¼é«çº§åºç¨ï¼1-2 å¨ï¼\n\n#### 4.1 ä¸ Hive çéæ\n- è¯»å Hive è¡¨å¹¶è¿è¡å¤ææ¥è¯¢\n- ä½¿ç¨ Hive UDFãHive å½æ°\n- Hive metastore éç½®ä¸ä½¿ç¨\n\n#### 4.2 ä¸ Hadoop çææ´å\n- ä¸ HDFSãHiveãKafkaãFlink ç­éæ\n- ä½¿ç¨ HiveQL å¨ Spark ä¸­æ§è¡\n- Spark SQL ä¸ Hive çå¼å®¹æ§é®é¢\n\n#### 4.3 é«çº§ç¹æ§\n- ç¨æ·èªå®ä¹å½æ°ï¼UDFï¼\n- çªå£å½æ°ï¼Window Functionsï¼\n- å¤ææ°æ®ç±»åï¼StructType, ArrayType, MapTypeï¼\n\n> ð§  ç¤ºä¾ï¼çªå£å½æ°\n```sql\nSELECT name, score,\n       RANK() OVER (ORDER BY score DESC) AS rank\nFROM scores;\n```\n\n---\n\n## ð§© ä¸ãå­¦ä¹ èµææ¨èï¼ç²¾éï¼\n\n### ð ä¹¦ç±\n- ãSpark SQL æå¨æåãï¼å®æ¹ææ¡£ + ä¹¦æ¬ç»åï¼\n- ãLearning Spark SQLãï¼O'Reillyï¼\n\n### ð¥ è§é¢è¯¾ç¨\n- [Coursera - Apache Spark](https://www.coursera.org/specializations/apache-spark)\n- [edX - Big Data with Spark](https://www.edx.org/)\n- [Udemy - Spark for Beginners](https://www.udemy.com/)\n\n### ð å¨çº¿ææ¡£\n- [Spark SQL å®æ¹ææ¡£](https://spark.apache.org/docs/latest/sql-programming-guide.html)\n- [DataCamp - Spark SQL æç¨](https://www.datacamp.com/)\n\n---\n\n## ð§  åãå­¦ä¹ è®¡åå»ºè®®ï¼æ¯å¨å®æï¼\n\n| å¨æ° | å­¦ä¹ åå®¹ |\n|------|----------|\n| ç¬¬1å¨ | Spark SQL åºç¡ï¼DataFrame APIãSQL æ¥è¯¢ï¼ |\n| ç¬¬2å¨ | æ°æ®è¯»åï¼CSVãParquetãHiveï¼ |\n| ç¬¬3å¨ | å®æé¡¹ç®ï¼ETL æµç¨ãç¨æ·è¡ä¸ºåæ |\n| ç¬¬4å¨ | æ§è½ä¼åï¼ç¼å­ãShuffleãCatalyst ä¼åå¨ï¼ |\n| ç¬¬5å¨ | ä¸ HiveãHadoop éæãé«çº§ç¹æ§ï¼UDFãçªå£å½æ°ï¼ |\n\n---\n\n## ð§© äºãç»ä¹ å»ºè®®\n\n- æ¯å¤©å 1-2 ä¸ªå°ç»ä¹ ï¼å¦ï¼è®¡ç®å¹³åå¼ãç»è®¡æå¸¸è®¿é®é¡µé¢ç­ï¼\n- æ¯å¨å®æä¸ä¸ªå°é¡¹ç®ï¼å¦ï¼ç¨æ·ç»ååæãè®¢åç»è®¡ï¼\n- å°è¯éè¯» Spark SQL æºç ï¼éç¹æ¯ Catalyst ä¼åå¨é¨åï¼\n\n---\n\n## ð å­ãå¦æä½ éè¦æå¸®ä½ å¶å®æ´è¯¦ç»çè®¡å\n\nä½ å¯ä»¥åè¯æä»¥ä¸ä¿¡æ¯ï¼\n\n1. ä½ ç®åçæ°´å¹³ï¼æ¯å¦æ Spark åºç¡ï¼ï¼\n2. ä½ å¸æå¨å¤é¿æ¶é´åè¾¾å°ä»ä¹ç®æ ï¼\n3. ä½ æ´å¾åäºåªç§å­¦ä¹ æ¹å¼ï¼ï¼çä¹¦ãè§é¢ãå®æé¡¹ç®ï¼ï¼\n4. ä½ æ¯å¦å·²ç»æç¹å®çå­¦ä¹ èµæºæææï¼\n\næä¼æ ¹æ®ä½ çéæ±ï¼ä¸ºä½ éèº«å®å¶ä¸ä»½ **ä¸å±å­¦ä¹ è®¡å**ï¼åæ¬æ¯æ¥å­¦ä¹ åå®¹ãæ¨èèµæºåç»ä¹ é¢ã\n\n---\n\næ³è¦å¼å§åï¼æ¬¢è¿éæ¶åè¯æä½ çå·ä½éæ± ð"
  },
  {
    "role": "user",
    "content": "我想学习spark"
  },
  {
    "role": "assistant",
    "content": "你好～我们来确认下你的学习需求吧～  \n你目前想学习的主题是什么？比如：大数据、Spark、Python 等。同时，请告诉我你的现有基础是零基础、入门、进阶还是精通？"
  }
]